{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\julianxu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,output_dim,num_layer,**kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layer = num_layer\n",
    "        super(CrossLayer,self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self,input_shape):\n",
    "        self.input_dim = input_shape[1]\n",
    "        # print(self.input_dim)\n",
    "        self.W = []\n",
    "        self.bias = []\n",
    "        for i in range(self.num_layer):\n",
    "            self.W.append(self.add_weight(shape=[self.input_dim,1],initializer = 'glorot_uniform',name='w_{}'.format(i),trainable=True))\n",
    "            self.bias.append(self.add_weight(shape=[self.input_dim,1],initializer = 'zeros',name='b_{}'.format(i),trainable=True))\n",
    "        self.built = True\n",
    "    def call(self,input):\n",
    "\n",
    "        x0 = tf.einsum('bij->bji',input) # output[j][i] = m[i][j]\n",
    "        # print(\"x0_shape\",x0.get_shape())\n",
    "        x1 = tf.einsum('bmn,bnk->bmk',input,x0)\n",
    "        cross = tf.einsum('bmn,nk->bmk',x1,self.W[0]) + self.bias[0] + input\n",
    "        \n",
    "        for i in range(1,self.num_layer):\n",
    "            x0 = tf.einsum('bij->bji',cross) # output[j][i] = m[i][j]\n",
    "            x1 = tf.einsum('bmn,bnk->bmk',input,x0)\n",
    "            cross = tf.einsum('bmn,nk->bmk',x1,self.W[i]) + self.bias[i] + cross\n",
    "        return cross\n",
    "        \n",
    "class Deep(tf.keras.layers.Layer):\n",
    "    def __init__(self,dropout_deep,deep_layer_sizes):\n",
    "        # input_dim = num_size + embed_size = input_size\n",
    "        super(Deep, self).__init__()\n",
    "        self.dropout_deep  = dropout_deep\n",
    "        # fc layer\n",
    "        self.deep_layer_sizes = deep_layer_sizes\n",
    "        # 神经网络方面的参数\n",
    "        for i in range(len(deep_layer_sizes)):\n",
    "            setattr(self, 'dense_' + str(i),tf.keras.layers.Dense(deep_layer_sizes[i]))\n",
    "            setattr(self, 'batchNorm_' + str(i),tf.keras.layers.BatchNormalization())\n",
    "            setattr(self, 'activation_' + str(i),tf.keras.layers.Activation('relu'))\n",
    "            setattr(self, 'dropout_' + str(i),tf.keras.layers.Dropout(dropout_deep[i]))\n",
    "        # last layer\n",
    "        self.fc = tf.keras.layers.Dense(128,activation=None,use_bias=True)\n",
    "        \n",
    "    def call(self,input):\n",
    "        y_deep = getattr(self,'dense_' + str(0))(input)\n",
    "        y_deep = getattr(self,'batchNorm_' + str(0))(y_deep)\n",
    "        y_deep = getattr(self,'activation_' + str(0))(y_deep)\n",
    "        y_deep = getattr(self,'dropout_' + str(0))(y_deep)\n",
    "        \n",
    "        for i in range(1,len(self.deep_layer_sizes)):\n",
    "            y_deep = getattr(self,'dense_' + str(i))(y_deep)\n",
    "            y_deep = getattr(self,'batchNorm_' + str(i))(y_deep)\n",
    "            y_deep = getattr(self,'activation_' + str(i))(y_deep)\n",
    "            y_deep = getattr(self,'dropout_' + str(i))(y_deep)\n",
    "        \n",
    "        output = self.fc(y_deep)\n",
    "        return output\n",
    "    \n",
    "class DCN(tf.keras.Model):\n",
    "    def __init__(self,num_feat,num_field,dropout_deep,deep_layer_sizes,embedding_size=10):\n",
    "        super().__init__()\n",
    "        self.num_feat = num_feat # F =features nums\n",
    "        self.num_field = num_field # N =fields of a feature \n",
    "        self.dropout_deep  = dropout_deep\n",
    "        \n",
    "        # Embedding 这里采用embeddings层因此大小为F* M F为特征数量，M为embedding的维度\n",
    "        feat_embeddings = tf.keras.layers.Embedding(num_feat, embedding_size, embeddings_initializer='uniform') # F * M \n",
    "        self.feat_embeddings = feat_embeddings\n",
    "        \n",
    "        self.crosslayer = CrossLayer(output_dim = 128,num_layer=8)\n",
    "    \n",
    "        self.deep = Deep(dropout_deep,deep_layer_sizes)\n",
    "        self.fc = tf.keras.layers.Dense(1,activation='sigmoid',use_bias=True)\n",
    "        \n",
    "    def call(self,feat_index,feat_value):\n",
    "        \n",
    "        # embedding part  feat_index = inputs为输入 feat_embeddings为一个layer。\n",
    "        feat_embedding_0 = self.feat_embeddings(feat_index) # Batch * N * M \n",
    "#         print(feat_value.get_shape())\n",
    "        feat_embedding = tf.einsum('bnm,bn->bnm',feat_embedding_0,feat_value)\n",
    "        # print(\"feat_embedding:\",feat_embedding.get_shape()) # 32 * 39 * 10\n",
    "        stack_input = tf.keras.layers.Reshape((1,-1))(feat_embedding)\n",
    "        # print(\"stack_input:\",stack_input.get_shape()) # 32 * 1 * 390\n",
    "        \n",
    "        x1 = self.crosslayer(stack_input)\n",
    "        x2 = self.deep(stack_input)\n",
    "        \n",
    "        x3 = tf.keras.layers.concatenate([x1,x2],axis=-1)\n",
    "        output = self.fc(x3)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_table('../data/Criteo/train.txt')\n",
    "train.columns=['label','I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9',\n",
    "       'I10', 'I11', 'I12', 'I13','C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7',\n",
    "       'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17',\n",
    "       'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_features=['I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9',\n",
    "       'I10', 'I11', 'I12', 'I13']\n",
    "dist_features = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7',\n",
    "       'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17',\n",
    "       'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_ = 10\n",
    "# dir_feat_dict_ = 'feat_dict_' + str(freq_) + '.pkl2'\n",
    "continuous_range_ = range(1, 14)\n",
    "categorical_range_ = range(14, 40)\n",
    "\n",
    "# 统计离散特征每个离散值出现的次数组成字典\n",
    "feat_cnt = Counter()\n",
    "with open('../data/Criteo/train.txt', 'r') as fin:\n",
    "    for line_idx, line in enumerate(fin):\n",
    "        features = line.rstrip('\\n').split('\\t')\n",
    "        for idx in categorical_range_:\n",
    "            if features[idx] == '': continue\n",
    "            feat_cnt.update([features[idx]])\n",
    "# Only retain discrete features with high frequency\n",
    "dis_feat_set = set() # 高频段的离散字符\n",
    "for feat, ot in feat_cnt.items():\n",
    "    if ot >= freq_:\n",
    "        dis_feat_set.add(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for continuous and discrete features\n",
    "feat_dict = {}\n",
    "tc = 1\n",
    "# Continuous features\n",
    "for idx in continuous_range_:\n",
    "    feat_dict[idx] = tc\n",
    "    tc += 1 # 代表占据一列\n",
    "\n",
    "# Discrete features\n",
    "cnt_feat_set = set()\n",
    "with open('../data/Criteo/train.txt', 'r') as fin:\n",
    "    for line_idx, line in enumerate(fin):\n",
    "        features = line.rstrip('\\n').split('\\t')\n",
    "        for idx in categorical_range_:\n",
    "            # 排除空字符和低频离散字符\n",
    "            if features[idx] == '' or features[idx] not in dis_feat_set:\n",
    "                continue\n",
    "            # 排除连续性数值\n",
    "            if features[idx] not in cnt_feat_set:\n",
    "                cnt_feat_set.add(features[idx])\n",
    "                # 获取种类数\n",
    "                feat_dict[features[idx]] = tc\n",
    "                tc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = []\n",
    "train_value = []\n",
    "train_idx = []\n",
    "\n",
    "continuous_range_ = range(1, 14)\n",
    "categorical_range_ = range(14, 40)\n",
    "cont_max_=[]\n",
    "cont_min_=[]\n",
    "for cf in cont_features:\n",
    "    cont_max_.append(max(train[cf]))\n",
    "    cont_min_.append(min(train[cf]))\n",
    "cont_diff_ = [cont_max_[i] - cont_min_[i] for i in range(len(cont_min_))]\n",
    "\n",
    "def process_line_(line):\n",
    "    features = line.rstrip('\\n').split('\\t')\n",
    "    feat_idx, feat_value, label = [], [], []\n",
    "\n",
    "    # MinMax Normalization\n",
    "    for idx in continuous_range_:\n",
    "        if features[idx] == '':\n",
    "            feat_idx.append(0)\n",
    "            feat_value.append(0.0)\n",
    "        else:\n",
    "            feat_idx.append(feat_dict[idx])\n",
    "            # 归一化\n",
    "            feat_value.append(round((float(features[idx]) - cont_min_[idx - 1]) / cont_diff_[idx - 1], 6))\n",
    "\n",
    "    # 处理离散型数据\n",
    "    for idx in categorical_range_:\n",
    "        if features[idx] == '' or features[idx] not in feat_dict:\n",
    "            feat_idx.append(0)\n",
    "            feat_value.append(0.0)\n",
    "        else:\n",
    "            feat_idx.append(feat_dict[features[idx]])\n",
    "            feat_value.append(1.0)\n",
    "    return feat_idx, feat_value, [int(features[0])]\n",
    "\n",
    "with open('../data/Criteo/train.txt', 'r') as fin:\n",
    "    for line_idx, line in enumerate(fin):\n",
    "\n",
    "        feat_idx, feat_value, label = process_line_(line)\n",
    "        train_label.append(label)\n",
    "        train_idx.append(feat_idx)\n",
    "        train_value.append(feat_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcn= DCN(num_feat=len(feat_dict) + 1, num_field=39, dropout_deep=[0.5, 0.5, 0.5],\n",
    "                deep_layer_sizes=[400, 400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_label,train_idx,train_value)).shuffle(10000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_one_step(model, optimizer, idx, value, label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        output = model(idx,value)\n",
    "        loss = loss_object(y_true=label, y_pred=output)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    grads = [tf.clip_by_norm(g, 100) for g in grads]\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(label,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_acc')\n",
    "\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n\n    <ipython-input-19-2e36f67267a5>:4 train_one_step  *\n        output = model(idx,value)\n    C:\\Users\\qiu\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:847 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n\n    TypeError: call() missing 1 required positional argument: 'feat_value'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-23b3fd2decea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mtrain_one_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdcn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtemplate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Epoch {}, Loss: {}, Accuracy: {}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     print (template.format(epoch+1,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    492\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1820\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1822\u001b[1;33m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1823\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2150\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2041\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2043\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    913\u001b[0m                                           converted_func)\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    903\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 905\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    906\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in converted code:\n\n    <ipython-input-19-2e36f67267a5>:4 train_one_step  *\n        output = model(idx,value)\n    C:\\Users\\qiu\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:847 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n\n    TypeError: call() missing 1 required positional argument: 'feat_value'\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "for epoch in range(EPOCHS):\n",
    "    for label, idx, value in train_ds:\n",
    "        train_one_step(dcn,optimizer,idx, value,label)\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}'\n",
    "    print (template.format(epoch+1,\n",
    "                             train_loss.result(),train_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
